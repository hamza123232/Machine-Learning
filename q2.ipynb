{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Datasets\n",
    "We will be using two datasets for the whole coursework: IRIS and MNIST. Both datasets will be downloaded directly in the notebook using the skdataset library. Keep in mind that you will need to be connected to Internet to be able to download the datasets. If you want to work offline, you are free to save your dataset to npy file locally and load them while offline although this is not officially supported.\n",
    "IRIS: The IRIS dataset contains the following features in order: sepal length, sepal width, petal length, petal width. Classes names are: Iris Setosa for label 0, Iris Versicolour for label 1, and Iris Virginica for label 2.\n",
    "MNIST: MNIST is a dataset composed of images of handwritten digits. The features of each image are the pixels themselves.\n",
    "The script will generate two subsets for each of the two datasets, a training subset (X_dataset and Y_dataset with dataset the name of the dataset) and a test subset (X_dataset_test and Y_dataset_test).\n",
    "We will test correctness of your code on Hidden set.\n",
    "Warning: as Hidden may have different dimensions from IRIS and MNIST, hard-coded solutions may not work, thus resulting in lower grades. You need to make sure that your code would work if applied on a different number of samples and a different number of features/pixels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn import datasets as skdataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "RAND_ST = 42\n",
    "random.seed(RAND_ST)\n",
    "#begin_test\n",
    "\n",
    "#end_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following cells are used to load both datasets, Iris and MNIST."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_iris_dataset(num_classes=2):\n",
    "    # Load the datadet from SkDataset\n",
    "    iris = skdataset.load_iris()\n",
    "    X = iris.data\n",
    "    Y = iris.target\n",
    "    # Reduce the number of classes\n",
    "    idx = Y < num_classes\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def load_mnist_dataset(num_classes=2):\n",
    "    # Load the datadet from SkDataset\n",
    "    X, Y = skdataset.fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "    Y = Y.astype(np.int64)\n",
    "    # Reduce the number of classes\n",
    "    idx = Y < num_classes\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def load_mnist_dataset_onevsall(class_id=7):\n",
    "    # Load the datadet from SkDataset\n",
    "    X, Y = skdataset.fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "    Y = Y.astype(np.int64)\n",
    "    # One versus all\n",
    "    idx = Y == class_id\n",
    "    Y[~idx] = 0\n",
    "    Y[idx] = 1\n",
    "    return X, Y\n",
    "## Functions for visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Functions for visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Data Loading\n",
    "X, Y = load_iris_dataset(num_classes=3)\n",
    "X_iris, X_iris_test, Y_iris, Y_iris_test = train_test_split(X, Y, test_size=0.1, random_state=RAND_ST) # 90% training and 10% test\n",
    "print(\"X:\",X.shape,\"Y\",Y.shape)\n",
    "X_iris = X_iris.reshape(540,1)\n",
    "# X_iris\n",
    "# x_train=np.arange(0,len(X),1)\n",
    "# y_iris = np.arrange(0,len(Y),1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Mnist dataset\n",
    "X, Y = load_mnist_dataset(num_classes=10)\n",
    "X = X / 255.0\n",
    "X_mnist, X_mnist_test, Y_mnist, Y_mnist_test = train_test_split(X, Y, test_size=0.1, random_state=RAND_ST) # 90% training and 10% test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Question #2\n",
    "2. Free form optimization (18 points)\n",
    "\n",
    "a) Implement Gradient Descent (GD) (3 points), Gradient Descent with Nesterov Momentum (GDN) (4 points) and a second order optimization method (4 points)\n",
    "b) Write the gradient and hessian of “paraboloid” and run the optimization methods on it (7 points on hidden test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Question 2.a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_descent(parameters, objective, d_objective, step_size, max_iterations, eps_change=1.0e-6):\n",
    "    \"\"\"\n",
    "    Write your own implementation of gradient descent here.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "    parameters:      init of parameters to optimize - R^N\n",
    "    objective:       function to minimize - R^N -> R^1\n",
    "    d_objective:     derivative of the function to minimize - R^N -> R^N\n",
    "    step_size:       step size/learning rate for the optimization algorithm - R^1\n",
    "    max_iterations:  maximum number of iterations to run the optimization algorithm - R^1 integer\n",
    "    eps_change:      minimum change of minimizer one step to the next before stopping - R^1\n",
    "\n",
    "    Return:\n",
    "    minimizer:    solution of the optimization\n",
    "    current_it:   iteration number at which the optimization reached the minimum\n",
    "    \"\"\"\n",
    "\n",
    "    N          = parameters.shape[0]\n",
    "    minimizer  = parameters.copy()\n",
    "    current_it = 0\n",
    "\n",
    "    #begin_solution\n",
    "\n",
    "    #end_solution\n",
    "\n",
    "\n",
    "    return minimizer, current_it + 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def second_order(parameters, objective, d_objective, dd_objective, step_size, max_iterations, eps_change):\n",
    "    \"\"\"\n",
    "    Write your own implementation of a second order optimizer.\n",
    "\n",
    "    Arguments:\n",
    "    parameters:      init of parameters to optimize - R^N\n",
    "    objective:       function to minimize - R^N -> R^1\n",
    "    d_objective:     function computing the derivative of the objective - R^N -> R^N\n",
    "    dd_objective:    function computing the second derivative of the objective - R^N -> R^NxN\n",
    "    step_size:       step size/learning rate for the optimization algorithm - R^1\n",
    "    max_iterations:  maximum number of iterations to run the optimization algorithm - R^1 integer\n",
    "    eps_change:      minimum change of minimizer one step to the next before stopping - R^1\n",
    "\n",
    "    Return:\n",
    "    minimizer:    solution of the optimization\n",
    "    current_it:   iteration number at which the optimization reached the minimum\n",
    "    \"\"\"\n",
    "\n",
    "    N          = parameters.shape[0]\n",
    "    minimizer  = parameters.copy()\n",
    "    current_it = 0\n",
    "\n",
    "    #begin_solution\n",
    "\n",
    "    #end_solution\n",
    "\n",
    "\n",
    "    return minimizer, current_it + 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def paraboloid(X): # paraboloid or saddle function X[0]^2-X[1]^2+X[2]^2 ...\n",
    "    tmp = np.power(X, 2)\n",
    "    return tmp[0::2].sum() - tmp[1::2].sum()\n",
    "\n",
    "def d_paraboloid(X):\n",
    "    gradient = np.zeros(X.shape[0])\n",
    "    #begin_solution\n",
    "\n",
    "    #end_solution\n",
    "\n",
    "    return gradient\n",
    "\n",
    "def dd_paraboloid(X):\n",
    "    hessian = np.eye(X.shape[0])\n",
    "    #begin_solution\n",
    "\n",
    "    #end_solution\n",
    "\n",
    "    return hessian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#begin_test\n",
    "\n",
    "#end_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters     = np.ones(1)\n",
    "objective      = square\n",
    "d_objective    = d_square\n",
    "step_size      = 0.1\n",
    "max_iterations = 100\n",
    "eps_change     = 1.0e-6\n",
    "\n",
    "gd_minimizer, gd_it = gradient_descent(parameters, objective, d_objective, step_size, max_iterations, eps_change)\n",
    "\n",
    "#begin_test\n",
    "\n",
    "#end_test\n",
    "\n",
    "\n",
    "parameters     = np.ones(1)\n",
    "objective      = square\n",
    "d_objective    = d_square\n",
    "momentum       = 0.4\n",
    "step_size      = 0.1\n",
    "max_iterations = 100\n",
    "eps_change     = 1.0e-6\n",
    "\n",
    "nesterov_minimizer, nesterov_it = gradient_descent_nesterov(parameters, objective, d_objective, momentum, step_size, max_iterations, eps_change)\n",
    "\n",
    "#begin_test\n",
    "\n",
    "#end_test\n",
    "\n",
    "\n",
    "parameters     = np.ones(1)\n",
    "objective      = square\n",
    "d_objective    = d_square\n",
    "dd_objective   = dd_square\n",
    "step_size      = 1.0\n",
    "max_iterations = 200\n",
    "eps_change     = 1.0e-6\n",
    "\n",
    "second_minimizer, second_it = second_order(parameters, objective, d_objective, dd_objective, step_size, max_iterations, eps_change)\n",
    "\n",
    "#begin_test\n",
    "\n",
    "#end_test\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters     = np.ones(1)\n",
    "objective      = paraboloid\n",
    "d_objective    = d_paraboloid\n",
    "step_size      = 0.1\n",
    "max_iterations = 100\n",
    "eps_change     = 1.0e-6\n",
    "\n",
    "gd_minimizer, gd_it = gradient_descent(parameters, objective, d_objective, step_size, max_iterations, eps_change)\n",
    "\n",
    "#begin_test\n",
    "\n",
    "#end_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#begin_test\n",
    "\n",
    "#end_test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}